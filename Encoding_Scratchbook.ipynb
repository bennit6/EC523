{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprocess as dp\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from modelhelper import MSE_Vec_matrix,gen_MSE_Vec\n",
    "import modelhelper\n",
    "\n",
    "#TODO Normalize Xtest\n",
    "#Make our own loss function\n",
    "\n",
    "# Hyperparameters\n",
    "# Batch Size, Num Epochs, Learning Rate, Momentum, FC Layer, Activation Function\n",
    "\n",
    "\n",
    "# 0 Lowercase & N2W\n",
    "# 1 Contractions\n",
    "# 2 Remove Punctutations\n",
    "# 3 Strop Words\n",
    "\n",
    "num_training = 1000000\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def accuracy(net, input_id, labels):\n",
    "    j = len(labels)\n",
    "\n",
    "    guesses = torch.argsort(net(input_id), dim=1, descending=True)\n",
    "#     print(\"GUESS: \", guesses[:,0])\n",
    "\n",
    "    # guess1 = torch.argmax(guesses, dim=1)\n",
    "    # guess2 = torch.argsort(guesses, dim=1)[-2]\n",
    "\n",
    "\n",
    "    # current_real = torch.tensor(labels)\n",
    "    current_real = labels.clone().detach()\n",
    "#     print(\"LABEL: \", current_real)\n",
    "\n",
    "    top1_acc = torch.sum(current_real==guesses[:,0])\n",
    "    top2_acc = torch.sum(current_real==guesses[:,1])\n",
    "\n",
    "\n",
    "    # print(guesses[:100])\n",
    "    # print(current_real[:100])\n",
    "    # print(\"Guess: \", guesses, \"Label: \", current_real)\n",
    "\n",
    "    accuracy_1 = top1_acc / j\n",
    "    accuracy_2 = (top2_acc + top1_acc) / j\n",
    "    # print(running_acc)\n",
    "    # print(j)\n",
    "\n",
    "#     print('Accuracy for top 1: %d %%' % ((accuracy_1) * 100.0))\n",
    "#     print('Accuracy for top 2: %d %%' % ((accuracy_2) * 100.0))\n",
    "\n",
    "    return accuracy_1, accuracy_2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "XPZGj9r3Hxh9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pylzma in /usr4/ugrad/jshteren/.local/lib/python3.6/site-packages (0.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.6.9/install/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !cd GitHub/EC523_Project/\n",
    "# !pip install transformers\n",
    "!pip install --upgrade pylzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.unpickle_data(r\"reviews_Electronics_5_7_encoded.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 768])\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "sentences = data['reviewText'][:num_training]\n",
    "labels = data['overall'][:num_training]\n",
    "print(sentences.shape)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.6.9/install/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-0c3c0f3e959e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.1, random_state=42, stratify=labels)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "print(device)\n",
    "\n",
    "X_test = torch.tensor(X_test).to(device)\n",
    "y_test = torch.tensor(y_test).to(device)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] = y_test[i] - 1 \n",
    "\n",
    "print(y_test)\n",
    "\n",
    "# indecies = torch.permute(indecies)\n",
    "# X_train = X_train[indexes,:]\n",
    "\n",
    "X_train = X_train.clone().detach()\n",
    "y_train = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev1 = X_train[y_train==1]\n",
    "rev2 = X_train[y_train==2]\n",
    "rev3 = X_train[y_train==3]\n",
    "rev4 = X_train[y_train==4]\n",
    "rev5 = X_train[y_train==5]\n",
    "\n",
    "training_points = min(len(rev1), len(rev2), len(rev3), len(rev4), len(rev5))\n",
    "\n",
    "rev1 = rev1 [:training_points]\n",
    "rev2 = rev2 [:training_points]\n",
    "rev3 = rev3 [:training_points]\n",
    "rev4 = rev4 [:training_points]\n",
    "rev5 = rev5 [:training_points]\n",
    "\n",
    "indicies = torch.randperm(training_points * 5)\n",
    "\n",
    "X_train = torch.cat((rev1, rev2, rev3, rev4, rev5), dim=0)[indicies, :]\n",
    "base = torch.zeros(training_points)\n",
    "y_train = torch.cat((base,base+1,base+2,base+3,base+4))[indicies]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dim=5, dropout=0.5,activation=F.sigmoid):\n",
    "\n",
    "        # self.loss = torch.nn.MSELoss()\n",
    "        super(Net, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "        self.fc1 = nn.Linear(768, 600)\n",
    "        self.fc2 = nn.Linear(600, 550)\n",
    "        self.fc3 = nn.Linear(550, 500)\n",
    "        self.fc4 = nn.Linear(500, 450)\n",
    "        self.fc5 = nn.Linear(450, 400)\n",
    "        self.fc6 = nn.Linear(400, 300)\n",
    "        self.fc7 = nn.Linear(300, 200)\n",
    "        self.fc8 = nn.Linear(200, 100)\n",
    "        self.fc9 = nn.Linear(100, 50)\n",
    "        self.fc10 = nn.Linear(50, output_dim)\n",
    "\n",
    "    #def forward(self, input_id, mask):\n",
    "    def forward(self, X_train):\n",
    "        activation = self.activation\n",
    "        x = self.dropout(X_train)\n",
    "        x = activation(self.fc1(x))\n",
    "        x = activation(self.fc2(x))\n",
    "        x = activation(self.fc3(x))\n",
    "        x = activation(self.fc4(x))\n",
    "        x = activation(self.fc5(x))\n",
    "        x = activation(self.fc6(x))\n",
    "        x = activation(self.fc7(x))\n",
    "        x = activation(self.fc8(x))\n",
    "        x = activation(self.fc9(x))\n",
    "        x = F.softmax(self.fc10(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 1.0000, 0.2000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2000, 1.0000, 0.2000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2000, 1.0000, 0.2000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2000, 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import modelhelper.MSE_Vec as test\n",
    "reload(modelhelper.MSE_Vec)\n",
    "\n",
    "# criterion = torch.nn.MSELoss().to(device)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "NUM_EPOCH = 200\n",
    "LR_START  = 1e-3\n",
    "LR_END    = 1e-3\n",
    "LR_GAMMA  = (LR_END/LR_START)**(1/NUM_EPOCH)\n",
    "\n",
    "net = Net(output_dim=5,dropout=0, activation=F.relu).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=LR_START, momentum=0.9)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=LR_START, momentum=0.8)\n",
    "# criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "scheduler = ExponentialLR(optimizer, gamma=LR_GAMMA)\n",
    "MSE_vec   = test.MSE_Vec_matrix(edge=0.2)\n",
    "MSE_vec.to(device)\n",
    "print(MSE_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)\n",
    "y_train = y_train.long().to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma = \\left( \\frac{\\alpha}{\\beta} \\right)^{\\frac{1}{e}}\n",
    "$$\n",
    "\n",
    "gamma is decay rate\n",
    "\n",
    "beta is start learning rate\n",
    "\n",
    "alpha is ending learning rate\n",
    "\n",
    "e is number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-6f4254e3bb0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#for i in range(1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindecies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.3/install/3.6/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:26"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "indecies = torch.tensor(range(batch_size))\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracy1 = []\n",
    "accuracy2 = []\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(y_train)//batch_size):\n",
    "    #for i in range(1):\n",
    "        select = batch_size * i + indecies\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_train[select,:])\n",
    "\n",
    "        # MSE Loss\n",
    "#         loss = criterion(outputs, gen_MSE_Vec(y_train[select],scale=4))\n",
    "#         loss = criterion(outputs, F.one_hot(y_train[select].long(),num_classes=5).float())\n",
    "\n",
    "        # Cross Entropy Loss\n",
    "        loss = criterion(outputs, y_train[select])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "#         training_loss = criterion(net(X_test),F.one_hot(y_test.long(),num_classes=5).float()).item()\n",
    "        loss = criterion(outputs, y_test[select].long()).item()\n",
    "        ac1,ac2 = accuracy(net, X_test, y_test)\n",
    "        accuracy1.append(ac1.item())\n",
    "        accuracy2.append(ac2.item())\n",
    "    print('[%d] loss: %.3f \\t test loss: %.3f \\t test_ac1: %.2f \\t test_ac2: %.2f' %\n",
    "        (epoch + 1, running_loss, training_loss*10,ac1,ac2))\n",
    "        \n",
    "    train_losses.append(running_loss)\n",
    "    test_losses.append(training_loss)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    scheduler.step()\n",
    "  \n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(train_losses)\n",
    "plt.figure()\n",
    "plt.plot(test_losses)\n",
    "plt.figure()\n",
    "plt.plot(accuracy1)\n",
    "plt.figure()\n",
    "plt.plot(accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def F_score(net, inputs, labels):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    output = net(inputs)\n",
    "    output = torch.argmax(output, dim=1).cpu().numpy()\n",
    "    y_pred.extend(output)\n",
    "    \n",
    "    y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    classes = ('1 Star', '2 Stars', '3 Stars', '4 Stars', '5 Stars')\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    #print(cf_matrix)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix)*10, index=[i for i in classes], columns = [i for i in classes])\n",
    "    plt.figure(figsize = (12,7))\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('output.png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0  3444]\n",
      " [    0     0     0     0  2490]\n",
      " [    0     0     0     0  4162]\n",
      " [    0     0     0     0 10167]\n",
      " [    0     0     0     0 29737]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "F_score(net, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Encoding_Scratchbook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
